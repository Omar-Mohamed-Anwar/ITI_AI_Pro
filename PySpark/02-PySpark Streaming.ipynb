{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.0.1/spark-3.0.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.0.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.1-bin-hadoop3.2\"\n",
        "import findspark\n",
        "findspark.init()\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder\\\n",
        "        .master(\"local\")\\\n",
        "        .appName(\"Colab\")\\\n",
        "        .config('spark.ui.port', '4050')\\\n",
        "        .getOrCreate()\n",
        "sc = pyspark.SparkContext.getOrCreate();"
      ],
      "metadata": {
        "id": "Bv-hNfEXkgKr"
      },
      "id": "Bv-hNfEXkgKr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "201cee8c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "201cee8c",
        "outputId": "4dd5e277-1f9a-4d3b-9050-6f07aff66208"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>pre { white-space: pre !important; }</style>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import display, HTML\n",
        "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efac8040",
      "metadata": {
        "id": "efac8040"
      },
      "source": [
        "### Create the schema of the streamed files (check the column names and types from the CSV files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4674d5d",
      "metadata": {
        "id": "c4674d5d"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import (StructType, StructField,\n",
        "                               StringType, IntegerType , FloatType , DateType)\n",
        "recordSchema = StructType([StructField('ID', IntegerType(), True),\n",
        "                           StructField('Date', DateType(), True),\n",
        "                           StructField('Open', FloatType(), True),\n",
        "                           StructField('High', FloatType(), True),\n",
        "                           StructField('Low', FloatType(), True),\n",
        "                           StructField('Close', FloatType(), True),\n",
        "                           StructField('Adj Close', FloatType(), True),\n",
        "                           StructField('Volume', IntegerType(), True)\n",
        "                           ])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f50fbeb",
      "metadata": {
        "id": "4f50fbeb"
      },
      "source": [
        "### Create the dataframe by reading the stream using format \"csv\" and the schema you created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "640364b9",
      "metadata": {
        "id": "640364b9"
      },
      "outputs": [],
      "source": [
        "df = spark.readStream.format(\"csv\")\\\n",
        "    .schema(recordSchema)\\\n",
        "    .load(\"InputStream/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce1e0e44",
      "metadata": {
        "id": "ce1e0e44"
      },
      "source": [
        "### Make sure the Dataframe is streaming the files from the folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fc0fa13",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fc0fa13",
        "outputId": "8f7b8e9e-8506-4c31-c619-9ce8832ed888"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ],
      "source": [
        "df.isStreaming"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac9d68de",
      "metadata": {
        "id": "ac9d68de"
      },
      "source": [
        "### Create a stream writer into memory and specify the query name \"stock:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f40bf944",
      "metadata": {
        "id": "f40bf944"
      },
      "outputs": [],
      "source": [
        "writer1 = df.writeStream.outputMode(\"append\") \\\n",
        "    .format(\"memory\") \\\n",
        "    .queryName(\"table1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63a5f9a4",
      "metadata": {
        "id": "63a5f9a4"
      },
      "source": [
        "### Start the write stream and make sure it works (read all columns from the table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d98c6dc",
      "metadata": {
        "id": "0d98c6dc"
      },
      "outputs": [],
      "source": [
        "query1 = writer1.start()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"SELECT * FROM table1\").show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cw8RUqgCsBUc",
        "outputId": "6ec225f3-3fbe-4735-9724-dc6debc947e2"
      },
      "id": "Cw8RUqgCsBUc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----------+-------+-------+-------+-------+---------+------+\n",
            "|  ID|      Date|   Open|   High|    Low|  Close|Adj Close|Volume|\n",
            "+----+----------+-------+-------+-------+-------+---------+------+\n",
            "|null|      null|   null|   null|   null|   null|     null|  null|\n",
            "| 120|2000-06-20|22817.9|23102.2|21680.6|22320.3|21092.633| 34466|\n",
            "| 121|2000-06-21|21893.8|22675.7|21680.6|22675.7|21428.484| 68651|\n",
            "| 122|2000-06-22|23386.6|23386.6|22462.5|23031.1|21764.336| 97209|\n",
            "| 123|2000-06-23|22107.1|24097.4|22107.1|22889.0|21630.053|199483|\n",
            "| 124|2000-06-26|23102.2|24168.5|22569.1|24026.3|22704.797|121969|\n",
            "| 125|2000-06-27|24026.3|25519.1|23742.0|24026.3|22704.797|113809|\n",
            "| 126|2000-06-28|23884.2|24666.1|23884.2|24666.1|23309.408| 86236|\n",
            "| 127|2000-06-29|25234.7|25234.7|23919.7|24239.6|22906.365| 45299|\n",
            "| 128|2000-06-30|24523.9|25092.6|23742.0|24879.3| 23510.88| 76670|\n",
            "+----+----------+-------+-------+-------+-------+---------+------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16908fa6",
      "metadata": {
        "id": "16908fa6"
      },
      "source": [
        "### Remove the first row from the data (hint: drop the rows where ALL values are null), then add a new column \"diff\", which is the difference between high and low columns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark.sql.functions as psf"
      ],
      "metadata": {
        "id": "gIDY6ytlu424"
      },
      "id": "gIDY6ytlu424",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df.dropna()"
      ],
      "metadata": {
        "id": "nbpfgIc9t-BJ"
      },
      "id": "nbpfgIc9t-BJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = df2.withColumn(\"diff\" , psf.col(\"High\") - psf.col(\"Low\"))"
      ],
      "metadata": {
        "id": "4P9TjOiut-n0"
      },
      "id": "4P9TjOiut-n0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer2 = df3.writeStream.outputMode(\"append\") \\\n",
        "    .format(\"memory\") \\\n",
        "    .queryName(\"table2\")"
      ],
      "metadata": {
        "id": "ML1q9d7evwWl"
      },
      "id": "ML1q9d7evwWl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query1.stop()"
      ],
      "metadata": {
        "id": "yqRnnR4iwLd-"
      },
      "id": "yqRnnR4iwLd-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query2 = writer2.start()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "liOGOZV4vw--",
        "outputId": "f860e22d-4067-4dc4-bbaa-79b8735e4eaf"
      },
      "id": "liOGOZV4vw--",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IllegalArgumentException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-120-566dde7cd90a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mquery2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwriter2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/streaming.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self, path, format, outputMode, partitionBy, queryName, **options)\u001b[0m\n\u001b[1;32m   1209\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueryName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueryName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1212\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.0.1-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                 \u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(e)\u001b[0m\n",
            "\u001b[0;31mIllegalArgumentException\u001b[0m: Cannot start query with name table2 as a query with that name is already active in this SparkSession"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"SELECT * FROM table2\").show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEtf1Tvjv-K-",
        "outputId": "9d2b7575-420b-4537-ee67-5748c481ea43"
      },
      "id": "eEtf1Tvjv-K-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------+-------+-------+-------+-------+---------+------+---------+\n",
            "| ID|      Date|   Open|   High|    Low|  Close|Adj Close|Volume|     diff|\n",
            "+---+----------+-------+-------+-------+-------+---------+------+---------+\n",
            "|120|2000-06-20|22817.9|23102.2|21680.6|22320.3|21092.633| 34466|1421.5996|\n",
            "|121|2000-06-21|21893.8|22675.7|21680.6|22675.7|21428.484| 68651| 995.0996|\n",
            "|122|2000-06-22|23386.6|23386.6|22462.5|23031.1|21764.336| 97209| 924.0996|\n",
            "|123|2000-06-23|22107.1|24097.4|22107.1|22889.0|21630.053|199483|1990.3008|\n",
            "|124|2000-06-26|23102.2|24168.5|22569.1|24026.3|22704.797|121969|1599.4004|\n",
            "|125|2000-06-27|24026.3|25519.1|23742.0|24026.3|22704.797|113809|1777.0996|\n",
            "|126|2000-06-28|23884.2|24666.1|23884.2|24666.1|23309.408| 86236| 781.9004|\n",
            "|127|2000-06-29|25234.7|25234.7|23919.7|24239.6|22906.365| 45299|   1315.0|\n",
            "|128|2000-06-30|24523.9|25092.6|23742.0|24879.3| 23510.88| 76670|1350.5996|\n",
            "|129|2000-07-03|24239.6|25590.2|24239.6|25092.6| 23712.45| 63306|1350.5996|\n",
            "+---+----------+-------+-------+-------+-------+---------+------+---------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query2.stop()"
      ],
      "metadata": {
        "id": "AlHZGq6CwXNe"
      },
      "id": "AlHZGq6CwXNe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "1f14581b",
      "metadata": {
        "id": "1f14581b"
      },
      "source": [
        "### Create a new write stream using the new generated dataframe and call the generate table \"modified_data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fb1be0e",
      "metadata": {
        "id": "9fb1be0e"
      },
      "outputs": [],
      "source": [
        "writer3 = df3.writeStream \\\n",
        "    .format(\"csv\") \\\n",
        "    .option(\"path\", \"/content/OutputStream/\") \\\n",
        "    .option(\"checkpointLocation\", \"/path/to/checkpoint/folder\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "969acbbc",
      "metadata": {
        "id": "969acbbc"
      },
      "outputs": [],
      "source": [
        "query3 = writer3.start()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query3.stop()"
      ],
      "metadata": {
        "id": "wNPM4ucry_1d"
      },
      "id": "wNPM4ucry_1d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modified_data = spark.readStream.format(\"csv\")\\\n",
        "    .schema(recordSchema)\\\n",
        "    .load(\"OutputStream/\")"
      ],
      "metadata": {
        "id": "ha59zs6FzM6a"
      },
      "id": "ha59zs6FzM6a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "453fbe76",
      "metadata": {
        "id": "453fbe76"
      },
      "outputs": [],
      "source": [
        "writer4 = df3.writeStream.outputMode(\"append\") \\\n",
        "    .format(\"memory\") \\\n",
        "    .queryName(\"table4\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query4 = writer4.start()"
      ],
      "metadata": {
        "id": "aunmpRHnzIvB"
      },
      "id": "aunmpRHnzIvB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"SELECT * FROM table4\").show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmotFHuVzhqe",
        "outputId": "64c96aff-84e0-4e68-a695-bede69626844"
      },
      "id": "TmotFHuVzhqe",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------+-------+-------+-------+-------+---------+------+---------+\n",
            "| ID|      Date|   Open|   High|    Low|  Close|Adj Close|Volume|     diff|\n",
            "+---+----------+-------+-------+-------+-------+---------+------+---------+\n",
            "|120|2000-06-20|22817.9|23102.2|21680.6|22320.3|21092.633| 34466|1421.5996|\n",
            "|121|2000-06-21|21893.8|22675.7|21680.6|22675.7|21428.484| 68651| 995.0996|\n",
            "|122|2000-06-22|23386.6|23386.6|22462.5|23031.1|21764.336| 97209| 924.0996|\n",
            "|123|2000-06-23|22107.1|24097.4|22107.1|22889.0|21630.053|199483|1990.3008|\n",
            "|124|2000-06-26|23102.2|24168.5|22569.1|24026.3|22704.797|121969|1599.4004|\n",
            "|125|2000-06-27|24026.3|25519.1|23742.0|24026.3|22704.797|113809|1777.0996|\n",
            "|126|2000-06-28|23884.2|24666.1|23884.2|24666.1|23309.408| 86236| 781.9004|\n",
            "|127|2000-06-29|25234.7|25234.7|23919.7|24239.6|22906.365| 45299|   1315.0|\n",
            "|128|2000-06-30|24523.9|25092.6|23742.0|24879.3| 23510.88| 76670|1350.5996|\n",
            "|129|2000-07-03|24239.6|25590.2|24239.6|25092.6| 23712.45| 63306|1350.5996|\n",
            "+---+----------+-------+-------+-------+-------+---------+------+---------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query4.stop()"
      ],
      "metadata": {
        "id": "QnAmwO2wzoGx"
      },
      "id": "QnAmwO2wzoGx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "e16c3036",
      "metadata": {
        "id": "e16c3036"
      },
      "source": [
        "### Write the generated data into files instead of the memory. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6441b76a",
      "metadata": {
        "id": "6441b76a"
      },
      "outputs": [],
      "source": [
        "writer5 = modified_data.writeStream \\\n",
        "    .format(\"csv\") \\\n",
        "    .option(\"path\", \"/content/OutputStream/\") \\\n",
        "    .option(\"checkpointLocation\", \"/path/to/checkpoint/folder\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query5 = writer5.start()"
      ],
      "metadata": {
        "id": "JGh5d5WSz24h"
      },
      "id": "JGh5d5WSz24h",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query5.stop()"
      ],
      "metadata": {
        "id": "CAOQaK70z7ru"
      },
      "id": "CAOQaK70z7ru",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "72f07e3f",
      "metadata": {
        "id": "72f07e3f"
      },
      "source": [
        "### Stop the query. Now, try reading the generated files into a normal dataframe\n",
        "- Create a schema and use it to read the data.\n",
        "- Show the output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec1321fe",
      "metadata": {
        "scrolled": false,
        "id": "ec1321fe"
      },
      "outputs": [],
      "source": [
        "finaldf = spark.read.csv(\"/content/OutputStream/part-00000-79dba7ef-bf98-4db8-ade0-de16d41445c1-c000.csv\",schema=recordSchema,header=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finaldf.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDMCCD_Q3bl8",
        "outputId": "4746bc04-5ffd-4181-eb8f-ef355042e022"
      },
      "id": "KDMCCD_Q3bl8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------+-------+-------+-------+-------+---------+------+\n",
            "| ID|      Date|   Open|   High|    Low|  Close|Adj Close|Volume|\n",
            "+---+----------+-------+-------+-------+-------+---------+------+\n",
            "|121|2000-06-21|21893.8|22675.7|21680.6|22675.7|21428.484| 68651|\n",
            "|122|2000-06-22|23386.6|23386.6|22462.5|23031.1|21764.336| 97209|\n",
            "|123|2000-06-23|22107.1|24097.4|22107.1|22889.0|21630.053|199483|\n",
            "|124|2000-06-26|23102.2|24168.5|22569.1|24026.3|22704.797|121969|\n",
            "|125|2000-06-27|24026.3|25519.1|23742.0|24026.3|22704.797|113809|\n",
            "|126|2000-06-28|23884.2|24666.1|23884.2|24666.1|23309.408| 86236|\n",
            "|127|2000-06-29|25234.7|25234.7|23919.7|24239.6|22906.365| 45299|\n",
            "|128|2000-06-30|24523.9|25092.6|23742.0|24879.3| 23510.88| 76670|\n",
            "|129|2000-07-03|24239.6|25590.2|24239.6|25092.6| 23712.45| 63306|\n",
            "|130|2000-07-04|25767.9|26087.7|25234.7|25448.0|24048.303| 45299|\n",
            "|131|2000-07-05|25448.0|25590.2|24523.9|25448.0|24048.303| 48816|\n",
            "|132|2000-07-06|25519.1|27367.3|25128.1|26585.3|25123.049|178662|\n",
            "|133|2000-07-07|27011.8|27154.0|26301.0|27011.8|25526.092|104103|\n",
            "|134|2000-07-10|27722.7|27722.7|26443.2|27011.8|25526.092|101570|\n",
            "|135|2000-07-11|27011.8|27011.8|26372.1|26514.2| 25055.86| 73716|\n",
            "|136|2000-07-12|26514.2|27935.9|26087.7|26869.7|25391.805|139976|\n",
            "|137|2000-07-13|26869.7|26940.8|26301.0|26407.6| 24955.12| 64994|\n",
            "|138|2000-07-14|25945.6|26407.6|25341.4|25803.4|24384.154| 75404|\n",
            "|139|2000-07-17|25803.4|25803.4|25803.4|25803.4|24384.154|     0|\n",
            "|140|2000-07-18|25021.5|25732.3|24879.3|24950.4| 23578.07| 48253|\n",
            "+---+----------+-------+-------+-------+-------+---------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4814d697",
      "metadata": {
        "id": "4814d697"
      },
      "source": [
        "### Sort the dataframe based on the ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c51d91a5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c51d91a5",
        "outputId": "dc50cb3e-2394-482b-d5e5-44a89ca4ef8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------+-------+-------+-------+-------+---------+------+\n",
            "| ID|      Date|   Open|   High|    Low|  Close|Adj Close|Volume|\n",
            "+---+----------+-------+-------+-------+-------+---------+------+\n",
            "|  0|2000-01-04|22817.9|25696.8|22817.9|24879.3| 23510.88|108745|\n",
            "|  1|2000-01-05|24523.9|26229.9|23670.9|24417.3|23074.295|175990|\n",
            "|  2|2000-01-06|24381.7|24666.1|22746.8|22817.9|21562.865| 71746|\n",
            "|  3|2000-01-07|22036.0|24879.3|22036.0|23884.2|22570.514|120984|\n",
            "|  4|2000-01-10|24879.3|25519.1|23813.1|24061.9| 22738.44|151371|\n",
            "|  5|2000-01-11|24168.5|25021.5|23955.2|24239.6|22906.365| 95943|\n",
            "|  6|2000-01-12|24168.5|24452.8|23457.6|23670.9|22368.947| 61899|\n",
            "|  7|2000-01-13|23670.9|24132.9|23102.2|23244.4|21965.906| 57538|\n",
            "|  8|2000-01-14|23457.6|24168.5|22746.8|23244.4|21965.906| 84267|\n",
            "|  9|2000-01-17|22533.6|23457.6|22533.6|23457.6|22167.377| 67807|\n",
            "| 10|2000-01-18|23457.6|23742.0|22746.8|23422.1|22133.832| 27995|\n",
            "| 11|2000-01-19|22817.9|23173.3|22036.0|22036.0| 20823.97| 44173|\n",
            "| 12|2000-01-20|21325.1|22000.4|20756.5|21680.6|20488.117| 47550|\n",
            "| 13|2000-01-21|21680.6|22391.4|20863.1|21680.6|20488.117| 80750|\n",
            "| 14|2000-01-24|20969.7|21822.7|20969.7|20969.7| 19816.32| 79906|\n",
            "| 15|2000-01-25|20258.9|20934.2|19548.0|20116.7|19010.236|170925|\n",
            "| 16|2000-01-26|20223.3|20543.2|19761.3|20330.0|19211.805| 59929|\n",
            "| 17|2000-01-27|20401.0|22746.8|20330.0|21040.8|19883.512|139132|\n",
            "| 18|2000-01-28|21431.8|22107.1|21040.8|21964.9|20756.783| 78640|\n",
            "| 19|2000-01-31|21325.1|21893.8|21183.0|21467.3|20286.553| 45861|\n",
            "+---+----------+-------+-------+-------+-------+---------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "finalDFSorted = finaldf.sort('ID')\n",
        "finalDFSorted.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}